{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30892f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f62380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea38cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import exp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9b2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_training = pd.read_csv(\"C:/Users/Calvi/Documents/Data Science Toolbox/Assessment 1/data/TrainingDataImputation.csv\")\n",
    "training_y = heart_disease_training.iloc[:, 0]\n",
    "heart_disease_training_indep = heart_disease_training\n",
    "del heart_disease_training_indep['HeartDiseaseorAttack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3369cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Training Dataset:\n",
      "        HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  Diabetes  \\\n",
      "0          1.0       0.5        1.0  0.27     0.5     0.5  0.333333   \n",
      "1          1.0       1.0        1.0  0.30     1.0     0.5  0.333333   \n",
      "2          1.0       1.0        1.0  0.27     1.0     0.5  0.333333   \n",
      "3          0.5       1.0        0.0  0.31     1.0     0.5  0.333333   \n",
      "4          1.0       1.0        1.0  0.28     1.0     1.0  0.333333   \n",
      "...        ...       ...        ...   ...     ...     ...       ...   \n",
      "412509     1.0       1.0        1.0  0.45     0.5     0.5  0.333333   \n",
      "412510     1.0       1.0        1.0  0.18     0.5     0.5  0.333333   \n",
      "412511     0.5       0.5        1.0  0.28     0.5     0.5  0.333333   \n",
      "412512     1.0       1.0        1.0  0.41     1.0     0.5  0.333333   \n",
      "412513     1.0       0.5        1.0  0.23     0.5     0.5  0.333333   \n",
      "\n",
      "        PhysActivity  Fruits  Veggies  ...  AnyHealthcare  NoDocbcCost  \\\n",
      "0                0.0     0.0      0.0  ...            1.0          0.5   \n",
      "1                0.5     1.0      1.0  ...            1.0          0.5   \n",
      "2                0.5     1.0      1.0  ...            1.0          0.0   \n",
      "3                0.5     0.5      0.5  ...            1.0          0.5   \n",
      "4                1.0     1.0      1.0  ...            1.0          1.0   \n",
      "...              ...     ...      ...  ...            ...          ...   \n",
      "412509           0.5     1.0      1.0  ...            1.0          0.5   \n",
      "412510           0.5     0.5      0.5  ...            1.0          0.5   \n",
      "412511           1.0     1.0      0.5  ...            1.0          0.5   \n",
      "412512           0.0     0.0      0.0  ...            1.0          0.5   \n",
      "412513           0.5     1.0      1.0  ...            1.0          0.5   \n",
      "\n",
      "         GenHlth  MentHlth  PhysHlth  DiffWalk  Sex       Age  Education  \\\n",
      "0       0.666667  0.032258  0.032258       1.0  0.0  1.000000   0.857143   \n",
      "1       1.000000  1.000000  1.000000       1.0  0.0  0.714286   0.857143   \n",
      "2       0.666667  0.032258  0.032258       0.5  1.0  1.000000   0.571429   \n",
      "3       0.666667  0.032258  0.000000       0.5  1.0  0.928571   0.428571   \n",
      "4       1.000000  0.000000  0.000000       1.0  1.0  0.714286   0.714286   \n",
      "...          ...       ...       ...       ...  ...       ...        ...   \n",
      "412509  0.666667  0.032258  0.193548       0.5  1.0  0.428571   1.000000   \n",
      "412510  0.833333  0.032258  0.032258       1.0  0.0  0.857143   0.428571   \n",
      "412511  0.333333  0.032258  0.032258       0.5  0.0  0.214286   0.857143   \n",
      "412512  0.833333  0.677419  0.032258       0.5  0.0  0.857143   0.714286   \n",
      "412513  0.666667  0.032258  0.032258       0.5  1.0  0.571429   0.857143   \n",
      "\n",
      "          Income  \n",
      "0       0.000000  \n",
      "1       0.222222  \n",
      "2       0.555556  \n",
      "3       0.444444  \n",
      "4       0.444444  \n",
      "...          ...  \n",
      "412509  0.888889  \n",
      "412510  0.555556  \n",
      "412511  0.333333  \n",
      "412512  0.666667  \n",
      "412513  0.222222  \n",
      "\n",
      "[412514 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Heart Disease Training Dataset:\")\n",
    "print(heart_disease_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0adcd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Training Classification:\n",
      "0         1.0\n",
      "1         1.0\n",
      "2         1.0\n",
      "3         1.0\n",
      "4         1.0\n",
      "         ... \n",
      "412509    0.0\n",
      "412510    0.0\n",
      "412511    0.0\n",
      "412512    0.0\n",
      "412513    0.0\n",
      "Name: HeartDiseaseorAttack, Length: 412514, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Heart Disease Training Classification:\")\n",
    "print(training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5987c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126e13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcafeatures(data,perc):\n",
    "    hd_scaled = StandardScaler().fit_transform(data)\n",
    "    features = hd_scaled.T\n",
    "    cov_matrix = np.cov(features)\n",
    "    values, vectors = np.linalg.eig(cov_matrix)\n",
    "    explained_variances = []\n",
    "    a = 0\n",
    "    num = 0\n",
    "    for i in range(len(values)):\n",
    "        explained_variances.append(values[i] / np.sum(values))\n",
    "    for i in range(len(explained_variances)):\n",
    "        while a < perc:\n",
    "            a += explained_variances[i]*100\n",
    "            num += 1\n",
    "    pc_feat = ['PC{}'.format(i+1) for i in range(num)]\n",
    "    return pc_feat,num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3492ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \n",
    "    def __init__(self,X):\n",
    "        self.n_components = pcafeatures(X, 95)[1]\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        \n",
    "    def fit(self,X):\n",
    "        # mean\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X = X-self.mean\n",
    "        # covariance\n",
    "        cov = np.cov(X.T)\n",
    "        # eigenvectors, eigenvalues\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "        # v[:, i]\n",
    "        # sort eigenvectors\n",
    "        eigenvectors = eigenvectors.T\n",
    "        idxs = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idxs]\n",
    "        eigenvectors = eigenvectors[idxs]\n",
    "        \n",
    "        # store first n eigenvectors\n",
    "        self.components = eigenvectors[0:self.n_components]\n",
    "        \n",
    "    def transform(self,X):\n",
    "        X = X - self.mean\n",
    "        return np.dot(X, self.components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f67a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(heart_disease_training_indep)\n",
    "pca.fit(heart_disease_training_indep)\n",
    "hda_pca_tr = pca.transform(heart_disease_training_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6368396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA of Heart Disease Training Dataset:\n",
      "[[ 1.23049933  0.78767842 -0.37535516 ... -0.34321415  0.2977642\n",
      "  -0.14318878]\n",
      " [-0.15674317  0.6804508  -0.92494614 ...  0.34558831 -0.08096224\n",
      "   0.20903433]\n",
      " [-0.09306808 -0.50254292 -0.66936754 ... -0.26274617  0.30885442\n",
      "   0.18105975]\n",
      " ...\n",
      " [-0.04701631  0.39857191  0.42281489 ...  0.1399973  -0.14284745\n",
      "   0.30420101]\n",
      " [ 0.98766112  0.63285981 -0.65643159 ... -0.46548152 -0.17183657\n",
      "   0.10120914]\n",
      " [ 0.15395439 -0.43956448 -0.13403093 ...  0.21435531  0.29552384\n",
      "   0.08346948]]\n"
     ]
    }
   ],
   "source": [
    "print(\"PCA of Heart Disease Training Dataset:\")\n",
    "print(hda_pca_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6135a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a73e5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43fea5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(hda_pca_tr)\n",
    "hda_pca_tr = scaler.transform(hda_pca_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e4b51b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.18037732e-16 -1.58978541e-17  1.12910667e-15  2.08022089e-16\n",
      " -1.86653242e-16 -7.39108922e-17 -6.46958424e-16  4.37930036e-16]\n"
     ]
    }
   ],
   "source": [
    "print(hda_pca_tr.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hda_pca_tr = scaler.fit_transform(hda_pca_tr)\n",
    "hda_pca_tr1 = scaler.transform(hda_pca_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + exp(-z))\n",
    "\n",
    "def initialise_weights(dim):\n",
    "  # numpy.zeros_like function return an array of zeros with the same shape and type as a given array\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    log_loss = -1 * np.mean( y_true*np.log10(y_pred) + (1-y_true)*np.log10(1-y_pred))\n",
    "    return log_loss\n",
    "\n",
    "\n",
    "def gradient_dw(x, y, w, b, alpha, N): \n",
    "    dw = x * (y-sigmoid(np.dot(w.T,x)+b)) - ((alpha*w*w)/N)\n",
    "    return dw\n",
    "\n",
    "def gradient_db(x, y, w, b):\n",
    "    db = y-sigmoid(np.dot(w.T,x)+b)\n",
    "    return db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-20,20)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,sigmoid(x))\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, epochs, alpha, eta0):\n",
    "    w, b = initialise_weights(X_train[0])\n",
    "    N = len(X_train)\n",
    "    log_loss_train = []\n",
    "    log_loss_test = []\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        \n",
    "        for j in range(N):\n",
    "            grad_dw = gradient_dw(X_train[j], y_train[j], w, b, alpha, N)\n",
    "            grad_db = gradient_db(X_train[j], y_train[j], w, b)\n",
    "            w = np.array(w) + (eta0 * np.array(grad_dw))\n",
    "            b = b + (eta0 * grad_db)\n",
    "\n",
    "    # predict the output of x_train[for all data points in X_train] using w and b\n",
    "        predict_train = []\n",
    "        for m in range(len(y_train)):\n",
    "            z = np.dot(w, X_train[m])+b\n",
    "            predict_train.append(sigmoid(z)) \n",
    "    \n",
    "    # store all the train loss values in a list\n",
    "        train_loss = logloss(y_train, predict_train)\n",
    "\n",
    "    # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        predict_test = []\n",
    "        for m in range(len(y_test)):\n",
    "            z = np.dot(w, X_test[m])+b\n",
    "            predict_test.append(sigmoid(z))\n",
    "    \n",
    "    # store all the test loss values in a list\n",
    "        test_loss = logloss(y_test, predict_test)\n",
    "\n",
    "    # we can also compare previous loss and current loss, \n",
    "    #if loss is not updating then stop the process and return w,b\n",
    "        if log_loss_train and train_loss > log_loss_train[-1]: \n",
    "            return w, b, log_loss_train, log_loss_test \n",
    "    \n",
    "        log_loss_train.append(train_loss)\n",
    "        log_loss_test.append(test_loss)\n",
    "\n",
    "    return w, b, log_loss_train, log_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha  = 0.0001\n",
    "eta0   = 0.0001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, log_loss_train, log_loss_test = train(hda_pca_tr, training_y, hda_pca_tr1, training_y, epochs, alpha, eta0)\n",
    "\n",
    "print(\"weight coefficient is:\", w)\n",
    "print(\"y-intercept is:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88544c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    z = np.dot(w,X.T)+b\n",
    "    list = []\n",
    "    for i in sigmoid(z):\n",
    "            if i>0.5:\n",
    "                list.append(1)\n",
    "            else:\n",
    "                list.append(0)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62efe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_y = predict(hda_pca_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4700fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_test = pd.read_csv(\"https://raw.githubusercontent.com/erinp0/DST-Assessment-1/main/Erin%20Pollard/test_imputed.csv\")\n",
    "test_y = heart_disease_test.iloc[:, 0]\n",
    "heart_disease_test_indep = heart_disease_test\n",
    "del heart_disease_test_indep['HeartDiseaseorAttack']\n",
    "\n",
    "hda_pca_test= PCA(heart_disease_test_indep)\n",
    "pca.fit(heart_disease_test_indep)\n",
    "hda_pca_test = pca.transform(heart_disease_test_indep)\n",
    "hda_pca_tr = scaler.transform(hda_pca_tr)\n",
    "\n",
    "predict_test_y = predict(hda_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7292fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y,y_hat):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_hat[i]:\n",
    "            accuracy += 1\n",
    "        else:\n",
    "            continue\n",
    "    accuracy = accuracy/len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283069b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training accuracy:\", accuracy(training_y,predict_train_y))\n",
    "print(\"test accuracy:\", accuracy(test_y,predict_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06218888",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(0,50)\n",
    "y = train(hda_pca_tr, training_y, hda_pca_test, predict_test_y, int(x1), alpha, eta0)\n",
    "plt.plot(x1,y[2], label = \"Training loss\")\n",
    "plt.plot(x1,y[3], label = \"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Log loss vs training iterations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
